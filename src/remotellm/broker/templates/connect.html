{% extends "base.html" %}

{% block title %}Connect LLM - RemoteLLM{% endblock %}

{% block content %}
<h1 style="margin-bottom: 20px;">Connect Your LLM</h1>

<div class="alert alert-info">
    <strong>Share your local LLM!</strong> Run the RemoteLLM connector on any machine with an OpenAI-compatible LLM server to make it available through this broker.
</div>

<div class="card">
    <h2>How It Works</h2>
    <div style="display: flex; gap: 20px; flex-wrap: wrap;">
        <div style="flex: 1; min-width: 200px; text-align: center; padding: 15px; background: #f8f9fa; border-radius: 8px;">
            <div style="font-size: 2rem; margin-bottom: 10px;">1</div>
            <strong>Connect</strong>
            <p style="font-size: 0.9rem; color: #666; margin-top: 5px;">Run the connector without a token</p>
        </div>
        <div style="flex: 1; min-width: 200px; text-align: center; padding: 15px; background: #f8f9fa; border-radius: 8px;">
            <div style="font-size: 2rem; margin-bottom: 10px;">2</div>
            <strong>Pending</strong>
            <p style="font-size: 0.9rem; color: #666; margin-top: 5px;">Connector waits for admin approval</p>
        </div>
        <div style="flex: 1; min-width: 200px; text-align: center; padding: 15px; background: #f8f9fa; border-radius: 8px;">
            <div style="font-size: 2rem; margin-bottom: 10px;">3</div>
            <strong>Approved</strong>
            <p style="font-size: 0.9rem; color: #666; margin-top: 5px;">Admin approves, API key sent automatically</p>
        </div>
        <div style="flex: 1; min-width: 200px; text-align: center; padding: 15px; background: #f8f9fa; border-radius: 8px;">
            <div style="font-size: 2rem; margin-bottom: 10px;">4</div>
            <strong>Active</strong>
            <p style="font-size: 0.9rem; color: #666; margin-top: 5px;">Connector saves key and serves requests</p>
        </div>
    </div>
</div>

<div class="card">
    <h2>1. Install the Connector</h2>
    <p style="margin-bottom: 15px;">Clone and install the RemoteLLM connector on your machine:</p>
    <div class="code-block">
        <button class="copy-btn" onclick="copyToClipboard(document.getElementById('install-cmd').textContent, this)">Copy</button>
        <pre id="install-cmd"># Clone the repository
git clone https://github.com/viljo/RemoteLLMconnector.git
cd RemoteLLMconnector

# Install with uv (recommended)
uv sync

# Or with pip
pip install -e .</pre>
    </div>
</div>

<div class="card">
    <h2>2. Run the Connector</h2>
    <p style="margin-bottom: 15px;">Start the connector pointing to your local LLM server:</p>
    <div class="code-block">
        <button class="copy-btn" onclick="copyToClipboard(document.getElementById('run-cmd').textContent, this)">Copy</button>
        <pre id="run-cmd">remotellm-connector \
  --llm-url http://localhost:11434 \
  --broker-url {{ ws_url }} \
  --connector-name "My Home Server"</pre>
    </div>

    <div class="alert alert-info" style="margin-top: 15px;">
        <strong>First Run:</strong> The connector will enter <em>pending</em> state. Ask an admin to approve your connector at <a href="/admin/connectors">/admin/connectors</a>. Once approved, your API key is automatically saved to <code>~/.remotellm/credentials.yaml</code>.
    </div>

    <div class="alert alert-success" style="margin-top: 15px;">
        <strong>Auto-Discovery:</strong> The connector automatically queries your LLM server's <code>/v1/models</code> or <code>/api/tags</code> endpoints to discover available models. No need to specify them manually!
    </div>
</div>

<div class="card">
    <h2>3. Command Line Options</h2>
    <table>
        <thead>
            <tr>
                <th>Parameter</th>
                <th>Description</th>
                <th>Example</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td><code>--llm-url</code></td>
                <td>URL of your local LLM API (OpenAI-compatible)</td>
                <td><code>http://localhost:11434</code></td>
            </tr>
            <tr>
                <td><code>--broker-url</code></td>
                <td>WebSocket URL of the broker</td>
                <td><code>{{ ws_url }}</code></td>
            </tr>
            <tr>
                <td><code>--connector-name</code></td>
                <td>Friendly name for your connector (shown in admin)</td>
                <td><code>"My GPU Server"</code></td>
            </tr>
            <tr>
                <td><code>--credentials-file</code></td>
                <td>Where to store the approved API key</td>
                <td><code>~/.remotellm/credentials.yaml</code></td>
            </tr>
            <tr>
                <td><code>--broker-token</code></td>
                <td>Pre-approved API key (optional, auto-obtained)</td>
                <td><code>ck-abc123...</code></td>
            </tr>
            <tr>
                <td><code>--model</code></td>
                <td>Override model names (optional, auto-discovered)</td>
                <td><code>llama-3.1-70b</code></td>
            </tr>
            <tr>
                <td><code>--log-level</code></td>
                <td>Logging verbosity</td>
                <td><code>DEBUG</code>, <code>INFO</code>, <code>WARNING</code></td>
            </tr>
            <tr>
                <td><code>--health-port</code></td>
                <td>Health check port (optional)</td>
                <td><code>8080</code></td>
            </tr>
        </tbody>
    </table>
</div>

<div class="card">
    <h2>4. Override Models (Optional)</h2>
    <p style="margin-bottom: 15px;">If auto-discovery doesn't work or you want to expose specific models, you can override:</p>
    <div class="code-block">
        <button class="copy-btn" onclick="copyToClipboard(document.getElementById('multi-cmd').textContent, this)">Copy</button>
        <pre id="multi-cmd">remotellm-connector \
  --llm-url http://localhost:8000 \
  --broker-url {{ ws_url }} \
  --connector-name "Custom Models" \
  --model llama-3.1-8b \
  --model llama-3.1-70b</pre>
    </div>
    <p style="margin-top: 10px; color: #666;">Note: If <code>--model</code> is specified, auto-discovery is disabled and only listed models are exposed.</p>
</div>

<div class="card">
    <h2>5. Systemd Service (Persistent)</h2>
    <p style="margin-bottom: 15px;">For persistent deployment, create a systemd service at <code>/etc/systemd/system/remotellm-connector.service</code>:</p>
    <div class="code-block">
        <button class="copy-btn" onclick="copyToClipboard(document.getElementById('systemd-cmd').textContent, this)">Copy</button>
        <pre id="systemd-cmd">[Unit]
Description=RemoteLLM Connector
After=network.target

[Service]
Type=simple
User=root
WorkingDirectory=/opt/remotellm
ExecStart=/usr/local/bin/remotellm-connector \
    --llm-url http://localhost:11434 \
    --broker-url {{ ws_url }} \
    --connector-name "My Server" \
    --credentials-file /root/.remotellm/credentials.yaml \
    --log-level INFO
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target</pre>
    </div>

    <p style="margin-top: 15px;">Enable and start the service:</p>
    <div class="code-block">
        <button class="copy-btn" onclick="copyToClipboard('sudo systemctl daemon-reload && sudo systemctl enable remotellm-connector && sudo systemctl start remotellm-connector', this)">Copy</button>
        <pre>sudo systemctl daemon-reload
sudo systemctl enable remotellm-connector
sudo systemctl start remotellm-connector</pre>
    </div>

    <div class="alert alert-info" style="margin-top: 15px;">
        <strong>First Start:</strong> On first run, the service will wait for admin approval. Check <code>journalctl -u remotellm-connector -f</code> for status. Once approved, credentials are saved and the service will reconnect automatically on restart.
    </div>
</div>

<div class="card">
    <h2>Supported LLM Servers</h2>
    <p style="margin-bottom: 15px;">The connector works with any OpenAI-compatible API:</p>
    <div class="grid grid-2">
        <div>
            <h3 style="margin-bottom: 10px;">llama.cpp</h3>
            <div class="code-block" style="font-size: 0.85rem;">
                <pre>./llama-server \
  --model model.gguf \
  --host 0.0.0.0 \
  --port 8000</pre>
            </div>
        </div>
        <div>
            <h3 style="margin-bottom: 10px;">Ollama</h3>
            <div class="code-block" style="font-size: 0.85rem;">
                <pre># Default endpoint
http://localhost:11434</pre>
            </div>
        </div>
        <div>
            <h3 style="margin-bottom: 10px;">vLLM</h3>
            <div class="code-block" style="font-size: 0.85rem;">
                <pre>vllm serve model-name \
  --host 0.0.0.0 \
  --port 8000</pre>
            </div>
        </div>
        <div>
            <h3 style="margin-bottom: 10px;">LM Studio</h3>
            <div class="code-block" style="font-size: 0.85rem;">
                <pre># Enable server in LM Studio
http://localhost:1234/v1</pre>
            </div>
        </div>
    </div>
</div>

<div class="card">
    <h2>Troubleshooting</h2>
    <table>
        <thead>
            <tr>
                <th>Issue</th>
                <th>Solution</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>Stuck in "pending" state</td>
                <td>Ask an admin to approve your connector at <a href="/admin/connectors">/admin/connectors</a></td>
            </tr>
            <tr>
                <td>Connection refused</td>
                <td>Check that your LLM server is running and accessible at the specified URL</td>
            </tr>
            <tr>
                <td>Authentication failed after approval</td>
                <td>Check that credentials file exists at <code>~/.remotellm/credentials.yaml</code> with correct permissions</td>
            </tr>
            <tr>
                <td>WebSocket disconnects</td>
                <td>Check network stability; the connector will auto-reconnect</td>
            </tr>
            <tr>
                <td>Model not appearing</td>
                <td>Ensure the model name matches exactly and the LLM server has the model loaded</td>
            </tr>
            <tr>
                <td>Revoked by admin</td>
                <td>Your connector was revoked. Credentials are cleared; reconnect to start a new approval request</td>
            </tr>
        </tbody>
    </table>
</div>
{% endblock %}
